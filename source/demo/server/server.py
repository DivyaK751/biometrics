from fastapi import FastAPI
from database import DataBaseConnector                                                                                                                                     
from tensorflow import keras
import numpy as np
from fastapi.middleware.cors import CORSMiddleware


app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
model = keras.models.load_model(r'1D_2XLSTM32_1x1_praneeth_150epochs_WS30.h5')
db=DataBaseConnector()

# @app.get("/my-first-api")
# def hello( name=None):
#     print(hello)
#     if name is None:
#         text = 'Hello!'

#     else:
#         text = 'Hello ' + name + '!'

#     return text

@app.get("/")
def check():
    return "connected"

@app.get("/updatedatabase")
def uploadtoDatabase(uid,data):
    print(data)
    try:
        db.insertInputData(email=str(uid), input=str(data))
        return "1"
    except:
        return "0"


# @app.get("/predict")
# def predictIsUser(data):   
#     data="""[(0.27165354330708663, 0.3228346456692913, 0.1415107250213623, 0.07248735427856445, 0.2622697353363037, 0.1207590103149414), (0.3228346456692913, 0.35039370078740156, 0.07248735427856445, 0.07475519180297852, 0.31853699684143066, 0.2460496425628662), (0.35039370078740156, 0.3110236220472441, 0.07475519180297852, 0.09013247489929199, 0.46248602867126465, 0.38773083686828613), (0.3110236220472441, 0.30708661417322836, 0.09013247489929199, 0.10371065139770508, 0.15209245681762695, 0.06195998191833496), (0.30708661417322836, 0.27165354330708663, 0.10371065139770508, 0.11824703216552734, 0.13737249374389648, 0.033661842346191406), (0.27165354330708663, 0.12598425196850394, 0.11824703216552734, 0.07837891578674316, 0.0776824951171875, -0.040564537048339844), (0.12598425196850394, 0.3031496062992126, 0.07837891578674316, 0.10432910919189453, 0.17231321334838867, 0.09393429756164551), (0.3031496062992126, 0.35039370078740156, 0.10432910919189453, 0.09959220886230469, 0.26851868629455566, 0.16418957710266113), (0.35039370078740156, 0.32677165354330706, 0.09959220886230469, 0.10344243049621582, 0.627037525177002, 0.5274453163146973), (0.32677165354330706, 0.27165354330708663, 0.10344243049621582, 0.14662671089172363, 0.16890788078308105, 0.06546545028686523), (0.27165354330708663, 0.2992125984251969, 0.14662671089172363, 0.048159122467041016, 0.148179292678833, 0.001552581787109375), (0.2992125984251969, 0.2755905511811024, 0.048159122467041016, 0.10193800926208496, 0.1284031867980957, 0.08024406433105469), (0.2755905511811024, 0.12598425196850394, 0.10193800926208496, 0.0944359302520752, 0.10292243957519531, 0.0009844303131103516), (0.12598425196850394, 0.31496062992125984, 0.0944359302520752, 0.09964919090270996, 0.2857687473297119, 0.19133281707763672), (0.31496062992125984, 0.3228346456692913, 0.09964919090270996, 0.09421443939208984, 0.41542553901672363, 0.31577634811401367), (0.3228346456692913, 0.2559055118110236, 0.09421443939208984, 0.10913586616516113, 0.10784411430358887, 0.013629674911499023), (0.2559055118110236, 0.30708661417322836, 0.10913586616516113, 0.09193778038024902, 0.14842605590820312, 0.03929018974304199), (0.30708661417322836, 0.27165354330708663, 0.09193778038024902, 0.12404108047485352, 0.17534899711608887, 0.08341121673583984), (0.27165354330708663, 0.27165354330708663, 0.12404108047485352, 0.1175081729888916, 0.12504076957702637, 0.0009996891021728516), (0.27165354330708663, 0.33070866141732286, 0.1175081729888916, 0.15830016136169434, 0.2658045291900635, 0.14829635620117188), (0.33070866141732286, 0.28346456692913385, 0.15830016136169434, 0.10421419143676758, 0.09432291984558105, -0.06397724151611328), (0.28346456692913385, 0.12598425196850394, 0.10421419143676758, 0.10222506523132324, 0.05497932434082031, -0.049234867095947266), (0.12598425196850394, 0.32677165354330706, 0.10222506523132324, 0.11214566230773926, 0.21386194229125977, 0.11163687705993652), (0.32677165354330706, 0.28346456692913385, 0.11214566230773926, 0.08595633506774902, 0.11720514297485352, 0.005059480667114258), (0.28346456692913385, 0.27165354330708663, 0.08595633506774902, 0.1202394962310791, 0.15655255317687988, 0.07059621810913086), (0.27165354330708663, 0.33070866141732286, 0.1202394962310791, 0.07312798500061035, 0.1232295036315918, 0.0029900074005126953), (0.33070866141732286, 0.33070866141732286, 0.07312798500061035, 0.09727931022644043, 0.11187362670898438, 0.03874564170837402), (0.33070866141732286, 0.35039370078740156, 0.09727931022644043, 0.0851597785949707, 0.14916324615478516, 0.05188393592834473), (0.35039370078740156, 0.12598425196850394, 0.0851597785949707, 
# 0.05813241004943848, 0.23895764350891113, 0.15379786491394043), (0.12598425196850394, 0.2755905511811024, 0.05813241004943848, 0.09868478775024414, 0.11265850067138672, 0.05452609062194824)]"""
#     try:
#         data = eval(data)
#         edata=[]
#         # return str(type(data))
#         # finalVec=[eval(i) for i in data]
#         for i in data:
#             edata.append(tuple(i))
#         # print(list(data))


#         print(edata)
#         finalVec = np.array(finalVec)
#         # finalVec = finalVec.reshape(1,30,6)
        
#         return str("com") 
#         # print(finalVec)
#         # finalVec = finalVec.reshape(1,30,6)
        # predictions = model.predict(x=eval(data),verbose= 1)
#         # print(predictions)
#     except:
#         return "errorfk"



# [(0.27165354330708663, 0.3228346456692913, 0.1415107250213623, 0.07248735427856445, 0.2622697353363037, 0.1207590103149414), (0.3228346456692913, 0.35039370078740156, 0.07248735427856445, 0.07475519180297852, 0.31853699684143066, 0.2460496425628662), (0.35039370078740156, 0.3110236220472441, 0.07475519180297852, 0.09013247489929199, 0.46248602867126465, 0.38773083686828613), (0.3110236220472441, 0.30708661417322836, 0.09013247489929199, 0.10371065139770508, 0.15209245681762695, 0.06195998191833496), (0.30708661417322836, 0.27165354330708663, 0.10371065139770508, 0.11824703216552734, 0.13737249374389648, 0.033661842346191406), (0.27165354330708663, 0.12598425196850394, 0.11824703216552734, 0.07837891578674316, 0.0776824951171875, -0.040564537048339844), (0.12598425196850394, 0.3031496062992126, 0.07837891578674316, 0.10432910919189453, 0.17231321334838867, 0.09393429756164551), (0.3031496062992126, 0.35039370078740156, 0.10432910919189453, 0.09959220886230469, 0.26851868629455566, 0.16418957710266113), (0.35039370078740156, 0.32677165354330706, 0.09959220886230469, 0.10344243049621582, 0.627037525177002, 0.5274453163146973), (0.32677165354330706, 0.27165354330708663, 0.10344243049621582, 0.14662671089172363, 0.16890788078308105, 0.06546545028686523), (0.27165354330708663, 0.2992125984251969, 0.14662671089172363, 0.048159122467041016, 0.148179292678833, 0.001552581787109375), (0.2992125984251969, 0.2755905511811024, 0.048159122467041016, 0.10193800926208496, 0.1284031867980957, 0.08024406433105469), (0.2755905511811024, 0.12598425196850394, 0.10193800926208496, 0.0944359302520752, 0.10292243957519531, 0.0009844303131103516), (0.12598425196850394, 0.31496062992125984, 0.0944359302520752, 0.09964919090270996, 0.2857687473297119, 0.19133281707763672), (0.31496062992125984, 0.3228346456692913, 0.09964919090270996, 0.09421443939208984, 0.41542553901672363, 0.31577634811401367), (0.3228346456692913, 0.2559055118110236, 0.09421443939208984, 0.10913586616516113, 0.10784411430358887, 0.013629674911499023), (0.2559055118110236, 0.30708661417322836, 0.10913586616516113, 0.09193778038024902, 0.14842605590820312, 0.03929018974304199), (0.30708661417322836, 0.27165354330708663, 0.09193778038024902, 0.12404108047485352, 0.17534899711608887, 0.08341121673583984), (0.27165354330708663, 0.27165354330708663, 0.12404108047485352, 0.1175081729888916, 0.12504076957702637, 0.0009996891021728516), (0.27165354330708663, 0.33070866141732286, 0.1175081729888916, 0.15830016136169434, 0.2658045291900635, 0.14829635620117188), (0.33070866141732286, 0.28346456692913385, 0.15830016136169434, 0.10421419143676758, 0.09432291984558105, -0.06397724151611328), (0.28346456692913385, 0.12598425196850394, 0.10421419143676758, 0.10222506523132324, 0.05497932434082031, -0.049234867095947266), (0.12598425196850394, 0.32677165354330706, 0.10222506523132324, 0.11214566230773926, 0.21386194229125977, 0.11163687705993652), (0.32677165354330706, 0.28346456692913385, 0.11214566230773926, 0.08595633506774902, 0.11720514297485352, 0.005059480667114258), (0.28346456692913385, 0.27165354330708663, 0.08595633506774902, 0.1202394962310791, 0.15655255317687988, 0.07059621810913086), (0.27165354330708663, 0.33070866141732286, 0.1202394962310791, 0.07312798500061035, 0.1232295036315918, 0.0029900074005126953), (0.33070866141732286, 0.33070866141732286, 0.07312798500061035, 0.09727931022644043, 0.11187362670898438, 0.03874564170837402), (0.33070866141732286, 0.35039370078740156, 0.09727931022644043, 0.0851597785949707, 0.14916324615478516, 0.05188393592834473), (0.35039370078740156, 0.12598425196850394, 0.0851597785949707, 
# 0.05813241004943848, 0.23895764350891113, 0.15379786491394043), (0.12598425196850394, 0.2755905511811024, 0.05813241004943848, 0.09868478775024414, 0.11265850067138672, 0.05452609062194824)]


@app.get("/predict")
def fmk(data):
#     data="""[(0.27165354330708663, 0.3228346456692913, 0.1415107250213623, 0.07248735427856445, 0.2622697353363037, 0.1207590103149414), (0.3228346456692913, 0.35039370078740156, 0.07248735427856445, 0.07475519180297852, 0.31853699684143066, 0.2460496425628662), (0.35039370078740156, 0.3110236220472441, 0.07475519180297852, 0.09013247489929199, 0.46248602867126465, 0.38773083686828613), (0.3110236220472441, 0.30708661417322836, 0.09013247489929199, 0.10371065139770508, 0.15209245681762695, 0.06195998191833496), (0.30708661417322836, 0.27165354330708663, 0.10371065139770508, 0.11824703216552734, 0.13737249374389648, 0.033661842346191406), (0.27165354330708663, 0.12598425196850394, 0.11824703216552734, 0.07837891578674316, 0.0776824951171875, -0.040564537048339844), (0.12598425196850394, 0.3031496062992126, 0.07837891578674316, 0.10432910919189453, 0.17231321334838867, 0.09393429756164551), (0.3031496062992126, 0.35039370078740156, 0.10432910919189453, 0.09959220886230469, 0.26851868629455566, 0.16418957710266113), (0.35039370078740156, 0.32677165354330706, 0.09959220886230469, 0.10344243049621582, 0.627037525177002, 0.5274453163146973), (0.32677165354330706, 0.27165354330708663, 0.10344243049621582, 0.14662671089172363, 0.16890788078308105, 0.06546545028686523), (0.27165354330708663, 0.2992125984251969, 0.14662671089172363, 0.048159122467041016, 0.148179292678833, 0.001552581787109375), (0.2992125984251969, 0.2755905511811024, 0.048159122467041016, 0.10193800926208496, 0.1284031867980957, 0.08024406433105469), (0.2755905511811024, 0.12598425196850394, 0.10193800926208496, 0.0944359302520752, 0.10292243957519531, 0.0009844303131103516), (0.12598425196850394, 0.31496062992125984, 0.0944359302520752, 0.09964919090270996, 0.2857687473297119, 0.19133281707763672), (0.31496062992125984, 0.3228346456692913, 0.09964919090270996, 0.09421443939208984, 0.41542553901672363, 0.31577634811401367), (0.3228346456692913, 0.2559055118110236, 0.09421443939208984, 0.10913586616516113, 0.10784411430358887, 0.013629674911499023), (0.2559055118110236, 0.30708661417322836, 0.10913586616516113, 0.09193778038024902, 0.14842605590820312, 0.03929018974304199), (0.30708661417322836, 0.27165354330708663, 0.09193778038024902, 0.12404108047485352, 0.17534899711608887, 0.08341121673583984), (0.27165354330708663, 0.27165354330708663, 0.12404108047485352, 0.1175081729888916, 0.12504076957702637, 0.0009996891021728516), (0.27165354330708663, 0.33070866141732286, 0.1175081729888916, 0.15830016136169434, 0.2658045291900635, 0.14829635620117188), (0.33070866141732286, 0.28346456692913385, 0.15830016136169434, 0.10421419143676758, 0.09432291984558105, -0.06397724151611328), (0.28346456692913385, 0.12598425196850394, 0.10421419143676758, 0.10222506523132324, 0.05497932434082031, -0.049234867095947266), (0.12598425196850394, 0.32677165354330706, 0.10222506523132324, 0.11214566230773926, 0.21386194229125977, 0.11163687705993652), (0.32677165354330706, 0.28346456692913385, 0.11214566230773926, 0.08595633506774902, 0.11720514297485352, 0.005059480667114258), (0.28346456692913385, 0.27165354330708663, 0.08595633506774902, 0.1202394962310791, 0.15655255317687988, 0.07059621810913086), (0.27165354330708663, 0.33070866141732286, 0.1202394962310791, 0.07312798500061035, 0.1232295036315918, 0.0029900074005126953), (0.33070866141732286, 0.33070866141732286, 0.07312798500061035, 0.09727931022644043, 0.11187362670898438, 0.03874564170837402), (0.33070866141732286, 0.35039370078740156, 0.09727931022644043, 0.0851597785949707, 0.14916324615478516, 0.05188393592834473), (0.35039370078740156, 0.12598425196850394, 0.0851597785949707, 
# 0.05813241004943848, 0.23895764350891113, 0.15379786491394043), (0.12598425196850394, 0.2755905511811024, 0.05813241004943848, 0.09868478775024414, 0.11265850067138672, 0.05452609062194824)]"""
    try:
        data=eval(data) 
        elist=[] 
        for i in data:
            elist.append(i)
        
        selist=np.array(elist)

        selist=selist.reshape(1,30,6)

        predictions = model.predict(x=selist,verbose= 1)

        
        value=np.array2string(np.round(predictions[0][1],7))
        fvalue=np.array2string(np.round(predictions[0][0],7))

        print(format(float(value), '.7f'))
        print(format(float(fvalue), '.7f'))


        return format(float(value), '.7f')
    except:
        return '0'
